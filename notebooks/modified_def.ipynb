{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b55e67",
   "metadata": {},
   "source": [
    "# Modified Definition Test\n",
    "This notebook seeks to test the modified definition to the disruptivity that I defined using chains of events. I am worried this definition will suck due to the variance of the Poisson distribution but who knows! The new method is outlined in this blog post:\n",
    "\n",
    "https://cfsenergy.atlassian.net/wiki/spaces/~6318cff19794410874c7744f/blog/2023/05/05/2788819001/Lecture+2+fr+Froude+3+Probabilities+3+7+05+2023\n",
    "\n",
    "We start with imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.optimize import minimize, LinearConstraint\n",
    "from scipy.interpolate import interp1d, LinearNDInterpolator\n",
    "\n",
    "# Move into the source directory for this notebook to work properly\n",
    "# Probably want a better way of doing this.\n",
    "import os\n",
    "import importlib\n",
    "os.chdir('../src/')\n",
    "\n",
    "# Import whatever we need\n",
    "import disruptivity as dis\n",
    "import probability as prob\n",
    "import vis.disruptivity_vis as dis_vis\n",
    "import vis.probability_vis as prob_vis\n",
    "from vis.plot_helpers import plot_subplot as plot\n",
    "import data_loader\n",
    "\n",
    "# Import tokamak Configuartions\n",
    "from tokamaks.cmod import CONFIG as CMOD\n",
    "from tokamaks.d3d import CONFIG as D3D\n",
    "\n",
    "importlib.reload(dis)\n",
    "importlib.reload(prob)\n",
    "importlib.reload(dis_vis)\n",
    "load_disruptions_mat = data_loader.load_disruptions_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ee21e",
   "metadata": {},
   "source": [
    "Loading is the same as before, we use the premade functions for disruptivity computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmod_df, cmod_indices = load_disruptions_mat('../data/CMod_disruption_warning_db.mat')\n",
    "n_shots = np.unique(cmod_df.shot).shape[0]\n",
    "n_shots_no_disrupt = np.unique(cmod_df.shot[cmod_indices['indices_no_disrupt']]).shape[0]\n",
    "n_shots_disrupt = np.unique(cmod_df.shot[cmod_indices['indices_disrupt']]).shape[0]\n",
    "assert n_shots_disrupt+n_shots_no_disrupt == n_shots, \\\n",
    "    'Number of disrupts plus number of non disruptions does not equal the total shot number'\n",
    "print(f'Total Shot Number: {n_shots}, Non-Disrupted Shots: {n_shots_no_disrupt}, Disrupted Shots: {n_shots_disrupt}')\n",
    "\n",
    "'''\n",
    "So my goal with this block of code is to find all the portions of flat top disrupted shots \n",
    "that are in flat tops. Should be simple enough.\n",
    "'''\n",
    "\n",
    "# Entry dictionary\n",
    "entry_dict_1D = {\n",
    "    'kappa': CMOD[\"entry_dict\"][\"kappa\"],\n",
    "    'ip': CMOD[\"entry_dict\"][\"ip\"],\n",
    "}\n",
    "\n",
    "entry_dict_2D = {\n",
    "    'kappa':CMOD['entry_dict']['kappa'],\n",
    "    'z_error':CMOD['entry_dict']['z_error'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce10ead6",
   "metadata": {},
   "source": [
    "Now, we can reuse the histogram binning code for variable timesteps that returns the data indices of data points for each bin. Since this new method essentially tries to compute the dt of subsequent data points, it is mechanically the same as the dt calculation for variable timestep as well! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc59dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get the histogram with the list of data entries.\n",
    "# There is no need for numerator and denominators, only histograms of all the data.\n",
    "hist = dis.indices_to_histogram(cmod_df, entry_dict_2D, cmod_indices['indices_flattop'], 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a71984",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_list, max_counter = prob.compute_dt_bin(cmod_df, hist, cmod_indices['indices_flattop'], tau=0, window=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_dt_list, non_dis_dt_list = prob.entry_list_to_arrays(entry_list, max_counter, hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_array = prob.find_disruptivity(dis_dt_list, non_dis_dt_list, guess = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd9b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot('cmod_ncrit_zerr_disruptivity_kaloyannis.png', dis_vis.subplot_disruptivity2d, (d_array, np.zeros(d_array.shape), hist.bin_edges, entry_dict_2D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac41bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the big crunch\n",
    "cmod_vde_shotlist = np.loadtxt(\"../data/cmod_vde_shotlist.txt\", dtype=int)\n",
    "\n",
    "# Parameter setup\n",
    "figtype = 'disruptivity_vde_kaloyannis'\n",
    "shotlist = None # set to None for no shotlist\n",
    "\n",
    "# Compute indices of interest\n",
    "indices_n_disrupt, indices_n_total = dis.get_indices_disruptivity(CMOD, cmod_df, cmod_indices, shotlist=shotlist)\n",
    "\n",
    "for entry in CMOD['entry_dict']:\n",
    "    # Scuffed but it works\n",
    "    if (entry!=\"n_over_ncrit\" and entry!=\"z_error\"):\n",
    "        continue\n",
    "    \n",
    "    # Create the entry dict\n",
    "    entry_dict = {entry:CMOD['entry_dict'][entry]}\n",
    "    \n",
    "    # Histogram the data\n",
    "    hist = dis.indices_to_histogram(cmod_df, entry_dict, indices_n_total, 25)\n",
    "    hist50 = dis.indices_to_histogram(cmod_df, entry_dict, indices_n_total, 25)\n",
    "    \n",
    "    # Continuity checks\n",
    "    entry_list, max_counter = prob.compute_dt_bin(cmod_df, hist, indices_n_total, tau=0, window=20)\n",
    "    entry_list50, max_counter50 = prob.compute_dt_bin(cmod_df, hist50, indices_n_total, tau=50, window=20)\n",
    "    \n",
    "    # More data prep\n",
    "    dis_dt_list, non_dis_dt_list = prob.entry_list_to_arrays(entry_list, max_counter, hist)\n",
    "    dis_dt_list50, non_dis_dt_list50 = prob.entry_list_to_arrays(entry_list50, max_counter50, hist50)\n",
    "    \n",
    "    # Minimize\n",
    "    d_array = prob.find_disruptivity(dis_dt_list, non_dis_dt_list, guess = 1)\n",
    "    d_array50= prob.find_disruptivity(dis_dt_list50, non_dis_dt_list50, guess = 1)\n",
    "    \n",
    "    # Compute Disruptivity and save the plot\n",
    "    args = (d_array, np.zeros(d_array.shape), hist.bin_edges, entry_dict)\n",
    "    fig, ax = plot(f'cmod_{entry}_{figtype}.png', dis_vis.subplot_disruptivity1d, args)\n",
    "    \n",
    "    # Compute Disruptivity and save the plot\n",
    "    args = (d_array50, np.zeros(d_array50.shape), hist50.bin_edges, entry_dict)\n",
    "    fig, ax = plot(f'cmod_{entry}_50_{figtype}.png', dis_vis.subplot_disruptivity1d, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cae52d",
   "metadata": {},
   "source": [
    "### Boundary avoidance time\n",
    "\n",
    "Soooo last time we did boundary avoidance we were using scipy stuff for 1d interpolator. I want to move away from that since we have the ability to compute these maps in N dimensions. Now the question is how do we do this. I think that the way to do it is to create a mask value that ummm fills the gaps in the data with a high disruptivity value. This of course implies that the disruptivity maps will push the control system away form unexplored regions. I don't know if we should do that in practice but it is the first thing i thought of and it is what I want to do ok so don't @ me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a3d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a disruptivity map of N dimensions and fill unvisited regions with a high disruptivity.\n",
    "# This means we need a sepearate mask for regions with no data and regions with effectively 0 disruptivity. \n",
    "# We want to avoid the situation where the disruptivity is so low that there are functionally no disruptions\n",
    "# and having the control system avoid these hyper stable scenarios.\n",
    "(d_array, np.zeros(d_array.shape), hist.bin_edges, entry_dict_1D)\n",
    "bin_centers = (np.array(hist.bin_edges)[:,1:]+np.array(hist.bin_edges)[:,:-1])/2\n",
    "\n",
    "# N dimensional meshgrid creation from the bin centers\n",
    "xx = np.meshgrid(*bin_centers)\n",
    "\n",
    "# NDINTERPOLATOR\n",
    "interper = scipy.interpolate.RegularGridInterpolator(bin_centers, d_array,\n",
    "                                                     method='linear',bounds_error=False,\n",
    "                                                     fill_value=1e2)\n",
    "# interpolated([[-1,0],[1.1,0]])\n",
    "\n",
    "help(scipy.interpolate.RegularGridInterpolator)\n",
    "# listypoo_centers = []\n",
    "# listypoo_d = []\n",
    "# for i, (d, center) in enumerate(zip(optimal_d,bin_centers)):\n",
    "#     if d!=0:\n",
    "#         listypoo_d.append(d)\n",
    "#         listypoo_centers.append(center)\n",
    "        \n",
    "# interper = interp1d(listypoo_centers,listypoo_d, kind='linear', fill_value='extrapolate')\n",
    "# test = np.linspace(0.8,2,100)\n",
    "# y = interper(test)\n",
    "# plt.semilogy(test,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098178c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5dfabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok so now lets look at probability of disruption for a pulse\n",
    "shot = 1120807032\n",
    "data = np.array(cmod_df[entry_dict_2D.keys()][cmod_df.shot == shot])\n",
    "y = prob.p_data(interper(data),0.1,True)\n",
    "\n",
    "# Assume the last data point is the disruption time\n",
    "disr_index = cmod_df.time_until_disrupt.index[cmod_df.shot == shot][-1]\n",
    "\n",
    "plt.plot(cmod_df.time[cmod_df.shot == shot],y, label=str(shot))\n",
    "plt.plot([cmod_df.time[disr_index],cmod_df.time[disr_index]],[0,1], '--', color='orange', label=\"Disruption Time\")\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Disruption Probability\")\n",
    "plt.ylim(-0,1.)\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40acf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmod_df.time_until_disrupt.index[cmod_df.shot == shot][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb60b63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
