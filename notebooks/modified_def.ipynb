{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b55e67",
   "metadata": {},
   "source": [
    "# Modified Definition Test\n",
    "This notebook seeks to test the modified definition to the disruptivity that I defined using chains of events. I am worried this definition will suck due to the variance of the Poisson distribution but who knows! The new method is outlined in this blog post:\n",
    "\n",
    "https://cfsenergy.atlassian.net/wiki/spaces/~6318cff19794410874c7744f/blog/2023/05/05/2788819001/Lecture+2+fr+Froude+3+Probabilities+3+7+05+2023\n",
    "\n",
    "We start with imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.optimize import minimize, LinearConstraint\n",
    "from scipy.interpolate import interp1d, LinearNDInterpolator\n",
    "\n",
    "# Move into the source directory for this notebook to work properly\n",
    "# Probably want a better way of doing this.\n",
    "import os\n",
    "import importlib\n",
    "os.chdir('../src/')\n",
    "\n",
    "# Import whatever we need\n",
    "import disruptivity as dis\n",
    "import vis.disruptivity_vis as dis_vis\n",
    "import vis.probability_vis as prob_vis\n",
    "from vis.plot_helpers import plot_subplot as plot\n",
    "import data_loader\n",
    "\n",
    "# Import tokamak Configuartions\n",
    "from tokamaks.cmod import CONFIG as CMOD\n",
    "from tokamaks.d3d import CONFIG as D3D\n",
    "\n",
    "importlib.reload(dis)\n",
    "importlib.reload(dis_vis)\n",
    "load_disruptions_mat = data_loader.load_disruptions_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ee21e",
   "metadata": {},
   "source": [
    "Loading is the same as before, we use the premade functions for disruptivity computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmod_df, cmod_indices = load_disruptions_mat('../data/CMod_disruption_warning_db.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2345168",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "So my goal with this block of code is to find all the portions of flat top disrupted shots \n",
    "that are in flat tops. Should be simple enough.\n",
    "'''\n",
    "\n",
    "# Entry dictionary\n",
    "entry_dict_1D = {\n",
    "    'kappa': CMOD[\"entry_dict\"][\"kappa\"],\n",
    "    'ip': CMOD[\"entry_dict\"][\"ip\"],\n",
    "}\n",
    "\n",
    "entry_dict_2D = {\n",
    "    'q95':CMOD['entry_dict']['q95'],\n",
    "    'n_e':CMOD['entry_dict']['n_e'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce10ead6",
   "metadata": {},
   "source": [
    "Now, we can reuse the histogram binning code for variable timesteps that returns the data indices of data points for each bin. Since this new method essentially tries to compute the dt of subsequent data points, it is mechanically the same as the dt calculation for variable timestep as well! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd9b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_trajectory(ax, dataframe, entry_dict, indices, shot):\n",
    "    \n",
    "    # Filter the datafram data to get the pulse of interest in the flattop\n",
    "    disruptive_indices = indices[\"indices_flattop_disrupt_in_flattop\"]\n",
    "    shotlist_bool = np.isin(dataframe.shot, [shot])\n",
    "    shot_indices = dataframe[shotlist_bool].index\n",
    "    overlap = np.array(np.intersect1d(disruptive_indices,shot_indices))\n",
    "    \n",
    "    # Get the entry information\n",
    "    entries = list(entry_dict.keys())\n",
    "    \n",
    "    # Plot the trajectory\n",
    "    ax.plot(dataframe[entries[0]][overlap], cmod_df[entries[1]][overlap], c='orange')\n",
    "    \n",
    "    # Re-apply axis labels and limits if needed.\n",
    "    ax.set_xlim(entry_dict_2D[entries[0]]['range'])\n",
    "    ax.set_ylim(entry_dict_2D[entries[1]]['range'])\n",
    "    ax.set_xlabel(entry_dict_2D[entries[0]]['axis_name'])\n",
    "    ax.set_ylabel(entry_dict_2D[entries[1]]['axis_name'])\n",
    "    \n",
    "# Computing the disruptivity and plotting the regular figure\n",
    "shotlist=None\n",
    "indices_n_disrupt, indices_n_total = dis.get_indices_disruptivity(CMOD, cmod_df, cmod_indices, shotlist=shotlist)\n",
    "args = dis.compute_disruptivity_likelihood(cmod_df, entry_dict_2D, indices_n_total, nbins=35, tau=50, window=25)\n",
    "fig,ax = plot('cmod_ncrit_zerr_disruptivity_kaloyannis.png', dis_vis.subplot_disruptivity2d, args)\n",
    "\n",
    "# Get a pulse's flat top data\n",
    "shot = 1140226001\n",
    "draw_trajectory(ax,cmod_df,entry_dict_2D,cmod_indices,shot)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336081fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_vis.plot_data_selection(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac41bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_crunch(dataframe, indices, shotlist, tokamak, figtype, nbins=25, tau=0, window=2):\n",
    "    for entry in tokamak['entry_dict']:\n",
    "        # Information Lines\n",
    "        print(\"Working on \"+entry)\n",
    "        \n",
    "        # Create the entry dict\n",
    "        entry_dict = {entry:tokamak['entry_dict'][entry]}\n",
    "        \n",
    "        # Get the tokamak name\n",
    "        name = tokamak['name']\n",
    "\n",
    "        # Compute Disruptivity and save the plot\n",
    "        args = dis.compute_disruptivity_likelihood(dataframe,\n",
    "                                                   entry_dict,\n",
    "                                                   indices,\n",
    "                                                   nbins=35,\n",
    "                                                   tau = tau,\n",
    "                                                   window = window,\n",
    "                                                  )\n",
    "        fig, ax = plot(f'{name}_{entry}_{figtype}.png', dis_vis.subplot_disruptivity1d, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the big crunch\n",
    "cmod_vde_shotlist = np.loadtxt(\"../data/cmod_vde_shotlist.txt\", dtype=int)\n",
    "\n",
    "# Parameter setup\n",
    "figtype = 'disruptivity_vde_kaloyannis'\n",
    "shotlist = None # set to None for no shotlist\n",
    "\n",
    "# Compute indices of interest\n",
    "indices_n_disrupt, indices_n_total = dis.get_indices_disruptivity(CMOD, cmod_df, cmod_indices, shotlist=shotlist)\n",
    "\n",
    "big_crunch(cmod_df, indices_n_total, shotlist, CMOD, figtype, nbins=25, tau=0, window=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cae52d",
   "metadata": {},
   "source": [
    "### Boundary avoidance time\n",
    "\n",
    "Soooo last time we did boundary avoidance we were using scipy stuff for 1d interpolator. I want to move away from that since we have the ability to compute these maps in N dimensions. Now the question is how do we do this. I think that the way to do it is to create a mask value that ummm fills the gaps in the data with a high disruptivity value. This of course implies that the disruptivity maps will push the control system away form unexplored regions. I don't know if we should do that in practice but it is the first thing i thought of and it is what I want to do ok so don't @ me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4bd53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a3d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a disruptivity map of N dimensions and fill unvisited regions with a high disruptivity.\n",
    "# This means we need a sepearate mask for regions with no data and regions with effectively 0 disruptivity. \n",
    "# We want to avoid the situation where the disruptivity is so low that there are functionally no disruptions\n",
    "# and having the control system avoid these hyper stable scenarios.\n",
    "d_array = args[0]\n",
    "bin_centers = (np.array(args[2])[:,1:]+np.array(args[2])[:,:-1])/2\n",
    "\n",
    "# N dimensional meshgrid creation from the bin centers\n",
    "xx = np.meshgrid(*bin_centers)\n",
    "\n",
    "# NDINTERPOLATOR\n",
    "# First, treat the masked values\n",
    "# No data is the max, no disruptions is min\n",
    "# All disruptions is max.\n",
    "interpolator_array = np.copy(d_array)\n",
    "d_min = d_array[d_array>0].min()\n",
    "d_max = d_array[d_array>0].max()\n",
    "interpolator_array[d_array==-1]= d_max\n",
    "interpolator_array[d_array==-2]= d_max\n",
    "interpolator_array[d_array==-3]= d_max\n",
    "print(\"Max Fill: \",d_max, \"Min Fill:\", d_min)\n",
    "\n",
    "# Now do the fill value being the maximum\n",
    "interper = scipy.interpolate.RegularGridInterpolator(bin_centers, interpolator_array,\n",
    "                                                     method='linear',bounds_error=False,\n",
    "                                                     fill_value=d_array.max())\n",
    "\n",
    "# Visualize the filling\n",
    "args2 = list(args)\n",
    "args2[0]=interpolator_array\n",
    "fig,ax = plot('vis_fill.png', dis_vis.subplot_disruptivity2d, args2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5dfabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok so now lets look at probability of disruption for a pulse\n",
    "shot = 1140226013\n",
    "data = np.array(cmod_df[entry_dict_2D.keys()][cmod_df.shot == shot])\n",
    "y = dis.p_data(interper(data),0.1,True)\n",
    "\n",
    "# Assume the last data point is the disruption time\n",
    "disr_index = cmod_df.time_until_disrupt.index[cmod_df.shot == shot][-1]\n",
    "\n",
    "plt.plot(cmod_df.time[cmod_df.shot == shot],y, label=str(shot))\n",
    "plt.plot([cmod_df.time[disr_index],cmod_df.time[disr_index]],[0,1], '--', color='orange', label=\"Disruption Time\")\n",
    "\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Disruption Probability\")\n",
    "plt.ylim(-0,1.)\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b9452a",
   "metadata": {},
   "source": [
    "### DIII-D Crunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb60b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokamaks.d3d import CONFIG as D3D\n",
    "d3d_df, d3d_indices = load_disruptions_mat('../data/d3d-db-220420.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f8cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setup\n",
    "figtype = 'disruptivity_likelihood'\n",
    "shotlist = None # set to None for no shotlist\n",
    "     \n",
    "# Compute indices of interest\n",
    "indices_n_disrupt, indices_n_total = dis.get_indices_disruptivity(D3D, d3d_df, d3d_indices, shotlist=shotlist)\n",
    "\n",
    "big_crunch(d3d_df, indices_n_total, shotlist, D3D, figtype, nbins=35, tau=350, window=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d3d_df['z_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df07615",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cmod_df['shot'][446000:475000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmod_df['shot'][465000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f12dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def subplot_trajectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c9896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmod_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(cmod_df['n_e']/1e19)\n",
    "test[test>70] = 0\n",
    "test[test<0] = 0\n",
    "plt.plot(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f427ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cmod_df['n_e']/1e19, range=[0,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95722bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
